# Data Mining Project

## Master 2 Informatique pour les sciences

### Professor: Konstantin TODOROV

### By

- [Cherif KHEFFACHE](https://github.com/kheffache-cherif),
- [Arezki KACIOUI](https://github.com/arezki-k),
- [Amir SHIRALI POUR](https://github.com/su6i)

---

## Jupyter Notebook Docker used in our project

`docker run --name ips -p 8888:8888 -v "Your local working directory":/ipsDataMining -w /ipsDataMining emasalari/datamining`

### Definitions

- **_Machine Learning_**

> “Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed.”  
> -Arthur Samuel

Arthur Lee Samuel (December 5, 1901 – July 29, 1990) was an American pioneer in the field of computer gaming and artificial intelligence. He popularized the term "machine learning" in 1959.

- **_Data mining_** is a process used by companies to turn raw data into useful information. By using software to look for patterns in large batches of data, businesses can learn more about their customers to develop more effective marketing strategies, increase sales and decrease costs.

- **_Artificial intelligence (AI)_**

- **_Deep Learning_**

## Useful resources

- [Docker tutorial](https://www.scalyr.com/blog/create-docker-image/)

- [Yale University](http://www.stat.yale.edu/~tba3/class_data/)

## Best Python libraries for _Machine Learning_, _Deep Learning_, _Web Scraping_ and _Automation_

- [Numpy](https://numpy.org)
  NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.

  At the core of the NumPy package, is the ndarray object. This encapsulates n-dimensional arrays of homogeneous data types, with many operations being performed in compiled code for performance.

- [SciPy](https://www.scipy.org)
  SciPy is Scientific computing tools for Python and a very popular library among Machine Learning enthusiasts as it contains different modules for optimization, linear algebra, integration and statistics.
  The SciPy ecosystem includes general and specialised tools for data management and computation, productive experimentation, and high-performance computing.
  pandas, providing high-performance, easy-to-use data structures.
  It includes the following collections:
  - SymPy, for symbolic mathematics and computer algebra.
  - NetworkX, is a collection of tools for analyzing complex networks.
  - scikit-image is a collection of algorithms for image processing.
  - scikit-learn is a collection of algorithms and tools for machine learning.
  - h5py and PyTables can both access data stored in the HDF5 format.
- [scikit-learn](https://scikit-learn.org)
  Scikit-learn is a free software machine learning library for the Python programming language.
  is one of the most popular ML libraries for classical ML algorithms. It is built on top of two basic Python libraries, viz., NumPy and SciPy. Scikit-learn supports most of the supervised and unsupervised learning algorithms. Scikit-learn can also be used for data-mining and data-analysis, which makes it a great tool who is starting out with ML.
- [TensorFlow](https://www.tensorflow.org)
  DescriptionTensorFlow is a free and open-source software library for machine learning developed by Google Brain Team.
- Theano
- [Keras](https://keras.io)
  Keras is a Python deep learning API. DescriptionKeras is an open-source library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library.
- [PyTorch](https://ai.facebook.com/tools/pytorch/)
  PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR).
- Pandas
- Matplotlib
- [fast.ai](https://www.fast.ai)
  fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. fastai is basically another layer on top of PyTorch that gives you a lot new functionality around your neural network, such as visualization methods for your data, more ways of loading and splitting data, infering the number of classes from the dataset your provide and it extends the training utilities by a concept called "callbacks" (which keras also has but pytorch doesn't).
- [CUDA](https://developer.nvidia.com/cuda-toolkit)
  Develop, Optimize and Deploy GPU-Accelerated Apps
- [CuPy](https://cupy.dev)
  CuPyA NumPy-compatible array library accelerated by CUDA
- [FastAPI](https://fastapi.tiangolo.com)
  FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints. FastAPI is properly fast when we compare it to other major Python frameworks like Flask and Django.
- [Selenium](https://www.selenium.dev)
  Selenium automates browsers.
- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
  Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.
- [lxml](https://lxml.de)
  lxml is the most feature-rich and easy-to-use library for processing XML and HTML in the Python language.
